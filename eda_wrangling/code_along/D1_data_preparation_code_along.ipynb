{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Key items for this class: <span style=\"color:red\">collinearity</span>, <span style=\"color:orange\">scaling</span>, <span style=\"color:yellow\">transformation</span>, <span style=\"color:green\">encoding</span>, <span style=\"color:blue\">get_dummies</span>, <span style=\"color:purple\">R2_score</span>](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Preparation](#toc1_)    \n",
    "  - [Why data preparation?](#toc1_1_)    \n",
    "  - [Data Cleaning](#toc1_2_)    \n",
    "  - [Data Exploration](#toc1_3_)    \n",
    "    - [Review numerical continuous variables](#toc1_3_1_)    \n",
    "    - [Review categorical and numerical discrete values](#toc1_3_2_)    \n",
    "    - [Review correlations between variables](#toc1_3_3_)    \n",
    "  - [Feature selection](#toc1_4_)    \n",
    "  - [Feature engineering](#toc1_5_)    \n",
    "  - [Data preprocessing](#toc1_6_)    \n",
    "    - [Numerical features transformation:](#toc1_6_1_)    \n",
    "    - [Numerical features scaling:](#toc1_6_2_)    \n",
    "    - [Categorical features encoding](#toc1_6_3_)    \n",
    "  - [Modelling](#toc1_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Data Preparation](#toc0_)\n",
    "\n",
    "Or how to make your data as informative as possible before making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just another day in the life of a data analyst...\n",
    "# What are the typical libraries we import?\n",
    "\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donation = pd.read_csv(\"https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/donation_data.csv\")\n",
    "\n",
    "# What do we first look at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Why data preparation?](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try running a linear regression without preparing our data\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Step 1 - Data\n",
    "\n",
    "# Step 2 - Model\n",
    "\n",
    "# Step 3 - Fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Data Cleaning](#toc0_)\n",
    "\n",
    "- Are there any nulls?\n",
    "- Are the values formatted correctly?\n",
    "- Which columns have almost no variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick review of NaN rows - basically trying to find a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- `NaNs`: \n",
    "- `Dtypes`: \n",
    "- `Unique values`: \n",
    "- `Unusual stats`: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the std of `date_insert_db` is very low, it seems like this is a column with almost no variance. This means that the feature will provide us with low information, the exception being when the \"different\" values are very correlated with big changes in the target variable, in which case they should be handled separately like we will see later with the `salary` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove no variance column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Data Exploration](#toc0_)\n",
    "\n",
    "- What is the distribution of my data?\n",
    "- Do any of my features have many outliers?\n",
    "- How is my target (`donation`) related to my features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical & categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Review numerical continuous variables](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot numerical variables\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkblue']\n",
    "\n",
    "# Create a loop for histogram plots\n",
    "\n",
    "# Create a loop for box plots\n",
    "\n",
    "# Adjust the height, width, and title of the layout\n",
    "fig.update_layout(height=200 * don_num.shape[1], width=1000, title_text=\"Numerical variables distributions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- `age` & `num_calls` have the same, [**uniform distribution**](https://statisticsbyjim.com/probability/uniform-distribution/)\n",
    "- `donation` seems to have a normal distribution\n",
    "- `salary` does indeed have a couple of people on the high-end. Whilst these are informally called outliers, they aren't wrong values (i.e. incorrectly typed values) but rather a different population, so we will treat them separately.\n",
    "- `time_since_donation` is very skewed to the right, suggesting that the dataset mainly has people who donated a long time ago. Seeing this, it seems reasonable to fill in the `NaN` values in the column with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`donation` - fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill time_since_donation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review column after filling\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "\n",
    "fig.update_layout(height=400, width=1000, title_text=\"Time since donation distribution post-filling\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`salary` - select rows from the same population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the first 20 salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where should we set the threshold for selecting salary entries?\n",
    "# For this dataset, let's say that 500K is a reasonable threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review new top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review column after removing \"outliers\"\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "\n",
    "fig.update_layout(height=400, width=1000, title_text=\"Salary distribution post-filling\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Review categorical and numerical discrete values](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot categorical variables\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkblue']\n",
    "\n",
    "# Create a loop for histogram plots\n",
    "\n",
    "# Adjust the height, width, and title of the layout\n",
    "fig.update_layout(height=300 * don_cat.shape[1], width=500, title_text=\"Categorical variables distributions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- `gender` is evenly distributed\n",
    "- There is no `city_code` data for rural citizens, so we might be better off changing the values in this column to look at whether a donor is in the city or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now clearly see that there are more donors in urban areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[Review correlations between variables](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation between features & target - What correlation do we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`age` and `num_calls` are very highly correlated (1!), so we need to:\n",
    "1. Choose either one of them for modelling.\n",
    "2. Figure out why they are so highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that donors start receiving yearly calls as soon as they turn 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both columns are equally correlated with the target so we can remove either of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll choose to keep age for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should also remove the extra column we created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Feature selection](#toc0_)\n",
    "\n",
    "We already removed features that:\n",
    "- have no variance\n",
    "- are highly correlated with other features\n",
    "\n",
    "Now would be the time to further select features that are unlikely to contribute to our model. However, as we already have a small number of features, we can revisit this step after creating an initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Feature engineering](#toc0_)\n",
    "\n",
    "In this step we'd typically look to create new features from the current ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Data preprocessing](#toc0_)\n",
    "\n",
    "This section includes all necessary steps for running the model:\n",
    "- numerical features transformation (as needed)\n",
    "- numerical features scaling (as needed)\n",
    "- categorical features encoding (necessary for linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Numerical features transformation:](#toc0_)\n",
    "- This step is usually undertaken to reduce the skewness of a dataset, i.e. to increase the variance where it's very low. There are multiple types of transformations, some of the common types being square root, logarithm, and Box-Cox transformations.\n",
    "\n",
    "⚠️ Using any of these transformations does not change the underlying information of the feature ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the `salary` column is extremely skewed to the left so an appropriate transformation for this type of this distribution is a log-transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review column after log-transform\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "fig.update_layout(height=400, width=1000, title_text=\"Salary distribution post-transform\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we do the same for `time_since_donation`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's review the time_since_donation values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the `salary` column, `time_since_donation` has a lot of 365 days values rather than many values ranging between 360 and 365 days, so applying a log-transformation would not change the skewness of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the distribution would look like\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "fig.update_layout(height=400, width=1000, title_text=\"time_since_donation distribution post-transform\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_2_'></a>[Numerical features scaling:](#toc0_)\n",
    "- To understand the importance of our numerical features for the LR model, we need to scale our features, i.e. make it so that all features are in the same range, or have the same standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_3_'></a>[Categorical features encoding](#toc0_)\n",
    "- Models such as linear regression do not accept non-numerical values, so we need to convert those into numerical values by encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categoricals in a copy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch categoricals in copy df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ ALWAYS SET `drop_first=True` WHEN ONE-HOT ENCODING FOR LR ⚠️  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the features are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have all the possible values of a categorical feature (gender, city code, etc.) in the columns of a data frame, you can always infer what one of the column will be from the other columns. This is why we remove one of the unique elements when applying the `get_dummies` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply get_dummies on original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the features are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Modelling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This R2 score is really good! 🤩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
