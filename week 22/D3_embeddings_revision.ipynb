{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Embeddings](#toc1_)    \n",
        "  - [Finding similar words](#toc1_1_)    \n",
        "  - [Combining words to create new meaning](#toc1_2_)    \n",
        "    - [How does it work? Cosine similarity](#toc1_2_1_)    \n",
        "- [Resources](#toc2_)    \n",
        "- [Acknowledgements](#toc3_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Embeddings](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You know the drill\n",
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-i0XtkOg5myQ"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZA8sViHEBQf"
      },
      "outputs": [],
      "source": [
        "# The model I'd like to use but takes a very long time to download...\n",
        "# model_nope = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fXIyyppd6yDO"
      },
      "outputs": [],
      "source": [
        "# ...so we will try a smaller model\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Each word has an encoding, i.e. a number of abstract features that represent the word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s802Uz9gJqGU",
        "outputId": "e3edcec0-a8f7-4ead-e2b9-b011dbc65067"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.0083229,  0.3696   , -0.24436  , -0.89288  , -0.23607  ,\n",
              "       -0.41659  ,  0.48309  ,  0.91159  ,  0.14498  , -0.096963 ,\n",
              "        0.55061  ,  1.0376   ,  0.32243  , -0.01381  ,  0.0098052,\n",
              "       -0.66346  ,  0.27949  , -0.74099  , -0.29602  ,  0.64596  ,\n",
              "        1.1305   ,  0.54629  ,  0.49664  , -0.87378  ,  0.42399  ,\n",
              "        0.35015  , -1.9151   ,  0.010363 ,  0.35684  , -0.32398  ,\n",
              "       -0.66927  ,  0.43628  , -0.20924  ,  0.28862  ,  0.63752  ,\n",
              "       -0.18789  , -0.079442 ,  0.30494  ,  0.8829   , -0.3143   ,\n",
              "       -1.2595   , -0.72301  ,  0.077278 , -0.045894 ,  1.0251   ,\n",
              "        0.25472  , -0.2566   ,  0.18428  ,  0.34037  ,  0.53185  ,\n",
              "       -0.070906 ,  0.57464  ,  0.5131   ,  1.1666   ,  0.1848   ,\n",
              "       -1.4466   , -0.41846  ,  0.011812 ,  2.1553   ,  0.52012  ,\n",
              "       -0.9029   ,  0.43183  ,  0.60584  ,  0.72845  , -0.32243  ,\n",
              "        0.73929  , -0.68845  ,  0.25407  , -0.20834  , -0.059242 ,\n",
              "       -0.45655  , -0.27773  ,  0.7168   ,  0.075051 ,  0.41672  ,\n",
              "        0.77879  ,  0.38134  ,  0.19478  , -0.41434  ,  0.073975 ,\n",
              "       -0.043165 , -0.08107  ,  0.15718  ,  0.40069  , -0.23959  ,\n",
              "       -0.81604  , -0.027071 , -0.82597  , -0.49703  , -0.38626  ,\n",
              "       -0.20425  ,  0.23017  ,  0.664    , -0.43292  ,  0.576    ,\n",
              "       -0.16406  , -0.94914  ,  0.21461  ,  0.9313   , -0.41208  ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model['boat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model['boat'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_1_'></a>[Finding similar words](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Which enables you to search for \"similar\" words (words that could occupy the same vector space):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzbTfcKfI7aH",
        "outputId": "34ad6b5b-00ef-4dbe-82a1-c98224a8aeb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('boats', 0.8819124102592468),\n",
              " ('ship', 0.8258436322212219),\n",
              " ('vessel', 0.8200733661651611),\n",
              " ('ferry', 0.77042156457901),\n",
              " ('sailing', 0.7610524296760559),\n",
              " ('ships', 0.7407434582710266),\n",
              " ('capsized', 0.7383140921592712),\n",
              " ('barge', 0.7286107540130615),\n",
              " ('fishing', 0.7228102684020996),\n",
              " ('yacht', 0.7208371162414551)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('boat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGlpLAtnJXLn",
        "outputId": "79acc76f-5930-411e-baae-d61af9d23608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('books', 0.847648561000824),\n",
              " ('novel', 0.8181166648864746),\n",
              " ('published', 0.8023924231529236),\n",
              " ('story', 0.7941390872001648),\n",
              " ('author', 0.7937875390052795),\n",
              " ('wrote', 0.7930577397346497),\n",
              " ('essay', 0.7821518182754517),\n",
              " ('biography', 0.7754694819450378),\n",
              " ('written', 0.760090172290802),\n",
              " ('fiction', 0.7549652457237244)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('book')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_2_'></a>[Combining words to create new meaning](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G008d0IJE4k1",
        "outputId": "bb2ded8b-406f-4f96-e369-2b6dff4c88b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.7698540687561035)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# King is to man what ? is to woman:\n",
        "model.most_similar(positive=['woman','king'], negative=['man'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C9CzNNYE4n1",
        "outputId": "c306760c-68f6-4772-9ead-5a4acdd4149a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('girl', 0.9095936417579651)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Boy is to man what ? is to woman:\n",
        "model.most_similar(positive=['woman', 'boy'], negative=['man'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tycZXNw_HK4t",
        "outputId": "83110a70-74e8-419e-ef7c-e2f0029565fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('champagne', 0.6877999305725098)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Barley is to beer what grape is to ? :\n",
        "# model.most_similar(positive=['grape', 'beer'], negative=['barley'], topn=1)\n",
        "model.most_similar(positive=['grape', 'beer'], negative=['grain'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kauYhJxG2FP",
        "outputId": "d0f1e532-270e-40f1-df0f-17f3992e50cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('portugal', 0.806252121925354)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Madrid is to Spain what Lisbon is to ? :\n",
        "model.most_similar(positive=['lisbon', 'spain'],negative=['madrid'],topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_2_1_'></a>[How does it work? Cosine similarity](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDbFT9fCwwq",
        "outputId": "459269ba-3abb-405d-94d3-a9cf3c8ce24a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.02140226]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity([model['king']], [model['ufo']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCuIF_cJMJ-t",
        "outputId": "555a6a8a-2e07-4b59-c0df-69b223c093a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.8323495]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity([model['woman']],[model['man']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1jCRAAfL8nQ",
        "outputId": "42c558b1-4707-41f3-fdf4-ac8ee43a7678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.6647526]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity([model['king']],[model['crown']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axi2nj6sNfsf",
        "outputId": "de3f6213-124e-4c30-9b89-3f26e736f5f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.6977891]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity([model['king']],[model['monarch']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viOsYsQmLPu1",
        "outputId": "881b7aeb-5043-432c-e4a1-01220d9d72e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.70172185]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity([model['king'] - model['queen']], [model['son'] - model['daughter']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fczJjSO1DPB7",
        "outputId": "daf79f25-8181-4a8a-a979-c9b485622abc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.6088005]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity([model['russia'] - model['moscow']], [model['poland'] - model['krakow']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"Key 'lancut' not present in vocabulary\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Krakow is to Poland what ? is to Russia :\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrussia\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlancut\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoland\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\sabin\\anaconda3\\envs\\ml\\lib\\site-packages\\gensim\\models\\keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    844\u001b[0m ]\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\sabin\\anaconda3\\envs\\ml\\lib\\site-packages\\gensim\\models\\keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
            "\u001b[1;31mKeyError\u001b[0m: \"Key 'lancut' not present in vocabulary\""
          ]
        }
      ],
      "source": [
        "# Krakow is to Poland what ? is to Russia :\n",
        "model.most_similar(positive=['russia', 'lancut'],negative=['poland'],topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Resources](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [Word embeddings and Word2Vec, StatQuest (16 min)](https://www.youtube.com/watch?v=viZrOnJclY0)\n",
        "- [Cosine similarity, StatQuest (10 min)](https://www.youtube.com/watch?v=e9U0QAFbfLI)\n",
        "- Understanding transformers, by StatQuest:\n",
        "    - [Recurrent Neural Networks (RNNs) (17 min)](https://youtu.be/AsNTP8Kwu80?si=yLu1H5CEVd4dX7hm)  \n",
        "    - [Long Short-Term Memory Networks (LSTMs) (21 min)](https://youtu.be/YCzL96nL7j0?si=-i22L3FuAC6BWLSU)  \n",
        "    - [seq2seq Encoder-Decoder (17 min)](https://youtu.be/L8HKweZIOmg?si=ROsiu2V4A8EfWPjN)  \n",
        "    - [Attention for Neural Networks (16 min)](https://youtu.be/PSs6nxngL6k?si=Kk3U02Px3ij98RiX)  \n",
        "    - [Transformer Neural Networks (36 min)](https://youtu.be/zxQyTK8quyY?si=StA0ZLl702j3br4T)\n",
        "\n",
        "- [BERTopic library and documentation](https://maartengr.github.io/BERTopic/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Acknowledgements](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thank you, David Henriques, for your awesome lesson structure & content!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
