{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Web Communication Fundamentals](#toc1_1_)    \n",
    "    - [DNS, IP](#toc1_1_1_)    \n",
    "    - [HTTP](#toc1_1_2_)    \n",
    "    - [URL](#toc1_1_3_)    \n",
    "  - [HTTP Requests and Responses](#toc1_2_)    \n",
    "    - [Requests](#toc1_2_1_)    \n",
    "    - [Response](#toc1_2_2_)    \n",
    "- [What is Web Scraping](#toc2_)    \n",
    "- [Web structure](#toc3_)    \n",
    "  - [HTML](#toc3_1_)    \n",
    "    - [Exploring Web Page Structures](#toc3_1_1_)    \n",
    "    - [Fact 1: HTML is Built on Tags](#toc3_1_2_)    \n",
    "    - [Fact 2: Tags Can Have Attributes](#toc3_1_3_)    \n",
    "    - [Fact 3: Tags Can Be Nested](#toc3_1_4_)    \n",
    "    - [Selecting Specific Elements in Web Scraping](#toc3_1_5_)    \n",
    "- [Web Scraping with Python](#toc4_)    \n",
    "    - [Requests: Fetching a Web Page](#toc4_1_1_)    \n",
    "    - [Parsing HTML with Beautiful Soup](#toc4_1_2_)    \n",
    "      - [Extracting Data](#toc4_1_2_1_)    \n",
    "        - [**By Tag**](#toc4_1_2_1_1_)    \n",
    "        - [**By Class**](#toc4_1_2_1_2_)    \n",
    "        - [**By Tag and Class**](#toc4_1_2_1_3_)    \n",
    "        - [**Getting other attributes**](#toc4_1_2_1_4_)    \n",
    "      - [More filtering options](#toc4_1_2_2_)    \n",
    "        - [Filtering by Multiple Tags](#toc4_1_2_2_1_)    \n",
    "        - [Filtering by Multiple Classes](#toc4_1_2_2_2_)    \n",
    "        - [Combining Multiple Criteria](#toc4_1_2_2_3_)    \n",
    "        - [Limiting the Results](#toc4_1_2_2_4_)    \n",
    "        - [Navigating through the \"Tree\" of HTML Elements](#toc4_1_2_2_5_)    \n",
    "      - [Creating a DataFrame with the data](#toc4_1_2_3_)    \n",
    "      - [ðŸ’¡ Check for understanding](#toc4_1_2_4_)    \n",
    "      - [Scraping many pages](#toc4_1_2_5_)    \n",
    "      - [CSS selectors](#toc4_1_2_6_)    \n",
    "    - [More examples (self-guided)](#toc4_1_3_)    \n",
    "      - [BBC](#toc4_1_3_1_)    \n",
    "  - [Comments](#toc4_2_)    \n",
    "  - [Summary](#toc4_3_)    \n",
    "  - [Further materials](#toc4_4_)    \n",
    "    - [How to Solve a 403 Error](#toc4_4_1_)    \n",
    "    - [How to show an image from a URL](#toc4_4_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Web Communication Fundamentals](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![enjuto](https://www.publico.es/files/article_main/uploads//2014/12/13/548bb18f1d9ef.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[DNS, IP](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How do we connect to www.google.com?](https://www.youtube.com/watch?v=sUhEqT_HSBI&ab_channel=ProfeSang)\n",
    "* **DNS (Domain Name System)**: it's essentially the phonebook of the internet. Humans access information online through domain names, like \"google.com\". Web browsers, however, interact through Internet Protocol (IP) addresses. In this example, the DNS maps the internet address www.google.com to the server's IP: 216.58.222.196\n",
    " * **IP**: Server identification. A code that allows information to be sent and received by the correct parties\n",
    " * **Domain Providers**: Sell and purchase Internet domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[HTTP](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H**yper **T**ext **T**ransfer **P**rotocol\n",
    "- HTTP is a communications protocol that provides a structure for requests between the client and the server on a network.\n",
    "- For example, the web browser on the user's computer (the client) uses the HTTP protocol to request information from a website on a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[URL](#toc0_)\n",
    "Contains information about the resource being requested from the **server**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/data-bootcamp-v4/lessons/blob/main/img/http.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "- https://www.google.com/webhp?authuser=2\n",
    "- https://www.towardsdatascience.com\n",
    "- https://www.ironhack.com/\n",
    "    - Protocol: https (https == http is the same, but https is encrypted)\n",
    "    - Domain Name --> ironhack\n",
    "    - TLD (Top-Level Domain) --> .com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[HTTP Requests and Responses](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/data-bootcamp-v4/lessons/blob/main/img/request-response.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requests** and **responses** are fundamental components of the client-server communication model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Requests](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are queries or calls **sent by the client** (such as a web browser or other software) **to the server** in order to receive information (a **response**). \n",
    "\n",
    "A request typically consists of:\n",
    "- A method (such as GET, POST, PUT, DELETE) that defines the action to be performed\n",
    "     * GET: read the information of the resource, without modifying it in any way. Accessing the website from the browser **gets** information.\n",
    "- The URL or endpoint specifying the resource\n",
    "- Optional additional information such as:\n",
    "    - Headers (metadata): User-Agent, Accept-Language\n",
    "    - Parameters\n",
    "    - Body content. \n",
    "    \n",
    "For example, a client might send a GET request to retrieve information from a web page or a POST request to submit form data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Response](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the answers or data sent **by the server back to the client in reply to a request**. \n",
    "\n",
    "A response typically includes:\n",
    "- A status code that indicates the success or failure of the request\n",
    "- Headers with meta-information about the server's behavior\n",
    "- The actual content or data (if applicable), such as HTML, JSON (similar to a Python dictionary), images, or other media types.\n",
    "\n",
    "An important part of the **header** is the **status code**. This code is a numerical value that indicates the server's result. There are different status codes depending on whether the server has managed to carry out the request or has not managed to do anything. These are some groups of status codes:\n",
    "\n",
    "- **2xx successful**: the request was successfully received, understood, and accepted\n",
    "- **3xx redirection**: more actions are required to complete the request\n",
    "- **4xx client error**: the request contains incorrect syntax or cannot be fulfilled\n",
    "- **5xx server error**: the server has failed to complete an apparently valid request\n",
    "\n",
    "Complete list:\n",
    "https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
    "\n",
    "Much more fun:\n",
    "https://http.cat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[What is Web Scraping](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is a method employed by data analysts and developers to retrieve information from web pages. It involves fetching a web page and then parsing that page to obtain desired information. This technique is especially useful when the desired data isn't available through APIs. The extracted data can then be cleaned, analyzed, or stored in databases for further data analytics tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Web structure](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental web technologies that form the structure of the websites we aim to scrape are:\n",
    "\n",
    "- **HTML**: Standing as the backbone of almost all websites, HTML, the core markup language, is instrumental in creating web pages. It houses all the content available on a webpage.\n",
    "  \n",
    "- **CSS**: This stylesheet language works alongside HTML, taking charge of the presentation aspect of the webpages. It controls how HTML elements are displayed, setting the stage for a visually pleasing and organized web interface.\n",
    "\n",
    "- **JavaScript**: Adding a dynamic touch to the websites, JavaScript comes into play to create interactive and animated content. This programming language has the power to alter webpage content even after it has loaded, bringing a vivid and responsive element to web designs.\n",
    "\n",
    "In this lesson, we will work with the HTML from the websites.\n",
    "\n",
    "![html-css-javascript](https://imgs.search.brave.com/ru4Gn_cjhe4mwEOcd_Xk_foZHex9FeRpxDgMhQaiJJY/rs:fit:860:0:0/g:ce/aHR0cHM6Ly9odG1s/LWNzcy1qcy5jb20v/aW1hZ2VzL29nLmpw/Zw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[HTML](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of web scraping, understanding HTML (Hypertext Markup Language) is crucial.\n",
    "\n",
    "HTML is the standard markup language used to create web pages. Think of it as the skeleton or blueprint of a website. It structures content on the web, defining elements like paragraphs, headings, links, lists, and images. These elements are represented by \"tags\", which enclose content to give it meaning and context.\n",
    "\n",
    "When web scraping, you'll often navigate through this HTML structure to pinpoint and extract the exact data you need. Tools like web browsers' \"Inspect\" or \"View Source\" features allow you to see the underlying HTML of a page, which is invaluable when determining how to access specific pieces of content programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://imgs.search.brave.com/7aw6NAyYkPZ7Y_flOndmq9DcP5hVk0lIgTSYMS0EjaU/rs:fit:860:0:0/g:ce/aHR0cHM6Ly93d3cu/YWxzYWNyZWF0aW9u/cy5jb20veG1lZGlh/L2RvYy9vcmlnaW5h/bC9odG1sNS1iYXNp/Yy5wbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Exploring Web Page Structures](#toc0_)\n",
    "\n",
    "To inspect the underlying HTML of a web page, right-click anywhere on the page. Choose \"View Page Source\" in browsers like Chrome or Firefox. For Internet Explorer, it's \"View Source,\" and for Safari, select \"Show Page Source.\" (In Safari, if this option isn't visible, navigate to Safari Preferences, click on the Advanced tab, and enable \"Show Develop menu in menu bar.\")\n",
    "\n",
    "To embark on your web scraping journey, you just need to grasp **three foundational aspects** of HTML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Fact 1: HTML is Built on Tags](#toc0_)\n",
    "\n",
    "At its core, HTML is composed of content enveloped in `<tags>`. It typically houses the textual content we aim to scrape, adorned with these \"tags\" delineated by angle brackets. These tags provide structure and meaning, guiding the browser on how to display the content. The acronym \"HTML\" represents Hyper Text Markup Language.\n",
    "\n",
    "HTML follows a tree-like structure, encompassing parent tags, child tags, and sibling tags:\n",
    "```\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Page Title</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>My First Heading</h1>\n",
    "        <p>My first paragraph.</p>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "For instance, consider the `<strong>` tag, signaling bold formatting. If \"Jan. 21\" is encapsulated between an opening `<strong>` tag and its corresponding closing `</strong>` tag, it denotes where the bold styling begins and ends. This pair of tags instructs the browser to render the enclosed text, \"Jan. 21\", in bold.\n",
    "\n",
    "Tags come in various types, each suited to encapsulate specific content:\n",
    " * **Headings**: `<h1>`, `<h2>`, `<h3>`, `<hgroup>`...\n",
    " * **Phrasing**: `<b>`, `<img>`, `<sub>`...\n",
    " * **Embedded Content**: `<audio>`, `<img>`, `<video>`...\n",
    " * **Tabulated Data**: `<table>`, `<tr>`, `<tbody>`...\n",
    " * **Page Sections**: `<header>`, `<section>`, `<article>`...\n",
    " * **Metadata and Scripts**: `<meta>`, `<title>`, `<script>`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Fact 2: Tags Can Have Attributes](#toc0_)\n",
    "\n",
    "HTML tags can possess \"attributes,\" which are defined within the opening tag itself. \n",
    "\n",
    "Examine the following examples:\n",
    "\n",
    "- `<span class=\"short-desc\">`: Here, the `<span>` tag has a `class` attribute with the value \"short-desc\".\n",
    "- `<div> Zapas Marca Joma X54 </div>`: This tag doesn't contain any attributes.\n",
    "- `<div class=\"price-item\" id=\"offer\"> Zapas Marca Joma X54 </div>`: The `div` tag here has two attributes - `class` with the value \"price-item\" and `id` with the value \"offer\".\n",
    "- `<div class=\"text-monospace\" id=\"name_132\" href=\"www.example.com\"> Page Content </div>`: This `div` tag encompasses the following attributes:\n",
    "    + **class**: With the value \"text-monospace\". Remember, the class isn't unique across the page.\n",
    "    + **id**: With the value \"name_132\". IDs are meant to be unique identifiers for tags on the page.\n",
    "    + **href**: With the value \"www.example.com\". The href commonly represents a link to another section of the page or to an external website.\n",
    "\n",
    "**Key Notes**:\n",
    "- The `id` attribute should be unique for a tag; no two tags should share the same `id`.\n",
    "- The `class` attribute isn't meant to be unique. Instead, it often groups tags exhibiting similar behavior or styles.\n",
    "\n",
    "For web scraping purposes, **understanding the semantics** behind terms like `<span>`, `class`, or `short-desc` **isn't crucial**. The key takeaway is recognizing that tags can possess attributes and understanding their structural representation. When extracting content, our goal is to pinpoint the right tags within a webpage's HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other commonly used attributes in HTML**\n",
    "\n",
    "Several attributes in HTML provide additional information or modify elements. Some of these frequently used attributes include:\n",
    "\n",
    " * **`dir`**: Determines the text direction within an element, allowing for either forward or backward writing.\n",
    " * **`lang`**: Designates the language of the content within an element.\n",
    " * **`style`**: Applies inline styling to an element (Note: This shouldn't be mixed up with the `<style>` tag).\n",
    " * **`title`**: Offers supplementary details about an element, often displayed as a tooltip (Important: This is distinct from the `<title>` tag).\n",
    "\n",
    "...and many more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc3_1_4_'></a>[Fact 3: Tags Can Be Nested](#toc0_)\n",
    "\n",
    "Imagine the following segment of HTML code:\n",
    "\n",
    "`Hello <strong><em>Ironhack</em> students</strong>`\n",
    "\n",
    "Here, the phrase **Ironhack students** would be displayed in bold since it resides between the `<strong>` and `</strong>` tags. Additionally, the word ***Ironhack*** would be italicized due to the `<em>` tag, which signifies italic formatting. However, the word \"Hello\" remains unaffected by any formatting, as it lies outside both the `<strong>` and `<em>` tags. This results in the display:\n",
    "\n",
    "Hello ***Ironhack* students**\n",
    "\n",
    "This example illustrates a key principle: **tags influence the text from their opening to their closing points,** even if they are nested within other tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_5_'></a>[Selecting Specific Elements in Web Scraping](#toc0_)\n",
    "\n",
    "When diving into web scraping, it's essential to target specific elements efficiently. To hone in on the precise content you need, consider filtering tags based on:\n",
    " \n",
    " * **Tag Name**: The main type of the element (e.g., `<div>`, `<a>`, `<p>`).\n",
    " * **Class**: A descriptor that groups multiple elements with similar characteristics.\n",
    " * **ID**: A unique identifier assigned to a particular element.\n",
    " * **Other Attributes**: Additional properties like `href`, `title`, or `lang` that can further specify the elements of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Web Scraping with Python](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll use the `requests` library to fetch web pages and `BeautifulSoup` from the `bs4` package to parse these pages and extract information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you've installed the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should know by now what to do here ;)\n",
    "#!pip install requests beautifulsoup4\n",
    "#!pip install requests requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_1_'></a>[Requests: Fetching a Web Page](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `requests` library to fetch the content of a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Let's check out this website\n",
    "url = \"https://www.decathlon.com/collections/mountain-bikes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code retrieves the webpage content from the given URL and saves it in a `response` object. This object possesses either a `text` or `content` attribute, holding the HTML code similar to what we observe when inspecting the source in a web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interacting with APIs, we typically receive data in JSON format. However, web scraping provides us with HTML, which can be challenging to navigate. Fortunately, Beautiful Soup simplifies this process, making our work more manageable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_2_'></a>[Parsing HTML with Beautiful Soup](#toc0_)\n",
    "\n",
    "To parse the HTML, we'll employ the renowned Python library, [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). For a deeper understanding of its functionalities, explore the [official documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "![what-soup](https://media.giphy.com/media/l0K42QFkQXQUkxZhS/giphy.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get a soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above parses the HTML (stored in `response.content`) into a special object called `soup` that the Beautiful Soup library understands. In other words, Beautiful Soup is **reading the HTML and making sense of its structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of soup do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I make my soup pretty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parsed HTML, we can now extract specific elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_1_'></a>[Extracting Data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find` and `findAll` (or its equivalent `find_all`) are methods used to search the soup tree for tags that match a certain criterion.\n",
    "\n",
    "1. **find**:\n",
    "    - Returns only the **first** tag that matches a given set of criteria.\n",
    "    - Useful when you know there's only one tag of interest or you only want the first occurrence.\n",
    "    - Example: If you have multiple `<p>` tags on a page and you use `soup.find('p')`, you'll get only the first `<p>` tag.\n",
    "\n",
    "2. **findAll (or find_all)**:\n",
    "    - Returns a **list** of tags that match the given criteria.\n",
    "    - Useful when you want to capture all occurrences of a particular tag or set of tags.\n",
    "    - Example: Using `soup.find_all('p')` will give you a list containing all `<p>` tags on the page.\n",
    "\n",
    "Here's a simple illustration:\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <body>\n",
    "        <p>First paragraph.</p>\n",
    "        <p>Second paragraph.</p>\n",
    "        <div>Some div.</div>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Using `find('p')` would return the \"First paragraph.\" while `find_all('p')` would return a list containing both \"First paragraph.\" and \"Second paragraph.\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at different ways of extracting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <p>First paragraph.</p>\n",
    "        <p>Second paragraph.</p>\n",
    "        <div>Some div.</div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretty soup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_1_1_'></a>[**By Tag**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a popular tag: `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first <title> tag on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the all <title> tags on the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_1_2_'></a>[**By Class**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for HTML elements by class in a webpage using BeautifulSoup, you can also use the `find` and `find_all` methods. \n",
    "\n",
    "1. **Using `find` method to get the first matching element**:\n",
    "   \n",
    "   ```python\n",
    "   result = soup.find(class_='your-class-name')\n",
    "   ```\n",
    "\n",
    "2. **Using `find_all` method to get a list of all matching elements**:\n",
    "\n",
    "   ```python\n",
    "   results = soup.find_all(class_='your-class-name')\n",
    "   ```\n",
    "   \n",
    "Note that we are using `class_` parameter because `class` is a reserved keyword in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive into our target URL and explore its structure. Our objective is to craft a dataframe populated with bicycle names and their corresponding prices. \n",
    "\n",
    "To pinpoint the exact tags housing this information, follow these steps:\n",
    "1. Navigate to the website in your browser.\n",
    "2. Locate a bicycle name, right-click on it, and choose 'Inspect'. This action will direct you to the element within the site's HTML. Identify the tags so we can extract our desired data.\n",
    "3. Repeat the same process for the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the bicycle names and prices will change depending on the newest bikes in the shop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter all elements which `class` is `de-ProductTile-title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the results of `class` `de-ProductTile-title` are all inside `h4` tags and we actually got the information we wanted. But what if the `class` `de-ProductTile-title` was inside different `tags` and we only want the results of the `tag h4`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_1_3_'></a>[**By Tag and Class**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup allows filtering results using combinations, such as filtering by tag and class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tags = soup.find_all(name=tag_name, class_=class_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a for loop to iterate over the results and do whatever we need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the names from the provided HTML content, you can:\n",
    "\n",
    "1. Use the `findAll` method to locate the `<h4>` tags with the specific class (`de-ProductTile-title` in this case).\n",
    "2. Extract the text from the found tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <h4> tags with class \"de-ProductTile-title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Findall returns a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type are the tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at how many elements we retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the actual text using .text or .getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get rid of all the white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list only with bicycle names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the price from the provided HTML content, you can:\n",
    "\n",
    "1. Use the `findAll` method to locate the `<span>` tags with the specific class (`js-de-ProductTile-currentPrice` in this case).\n",
    "2. Extract the text from the found tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <span> tag and get its text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the text for one price tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the text for all price tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_1_4_'></a>[**Getting other attributes**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access other attribute values such as hyperlinks (which are usually contained in the `href` attribute of `a` tags), you first locate the element using BeautifulSoup methods such as `find` or `find_all`, and then use the `.get()` method to retrieve the value of the attribute you're interested in. Here is a step-by-step explanation:\n",
    "\n",
    "1. **Locate the element**: Use `find` or `find_all` to locate the element(s) that contain the attribute you want to access.\n",
    "\n",
    "    ```python\n",
    "    link_element = soup.find('a', class_='link-class')\n",
    "    ```\n",
    "\n",
    "2. **Access the attribute**: Once you have the element, use the `.get()` method to access the attribute value.\n",
    "\n",
    "    ```python\n",
    "    link_url = link_element.get('href')\n",
    "    ```\n",
    "\n",
    "In the above snippet:\n",
    "- We first find the `a` element with the class `'link-class'`.\n",
    "- We then get the value of the `href` attribute which contains the hyperlink.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting the website, we saw that the bicycle title was a link. How can we get that link?\n",
    "Lets inspect the whole element containing the bicycle name instead of just the name. \n",
    "\n",
    "We can see that we have:\n",
    "    \n",
    "    <a class=\"de-u-linkClean js-de-ProductTile-link\" href=\"/collections/mountain-bikes/products/mountain-bike-275-rockrider-st-100-196952-192872\">\n",
    "        \n",
    "Note: this link will change depending on the newest bike in the shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <a> tag and get its href attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all the hyperlinks in a page, then extracting new hyperlinks as you visit the other pages is called **web crawling** and is what Google uses to map out all of the websites that you're looking for ðŸ‘€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_2_'></a>[More filtering options](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_2_1_'></a>[Filtering by Multiple Tags](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find elements with multiple possible tags, you can pass a list of tag names to `find_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <div> and <span> tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the classes in a certain tag\n",
    "classes_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_2_2_'></a>[Filtering by Multiple Classes](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find elements with multiple possible classes, you can pass a list of class names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all elements with class 'js-de-ProductTile-currentPrice' or 'de-ProductTile-title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_2_3_'></a>[Combining Multiple Criteria](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine multiple criteria by using the `attrs` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <div> or <span> tags with class \"class1\" or \"class2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_2_4_'></a>[Limiting the Results](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can limit the number of results returned by `find_all` using the `limit` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the first 5 matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc4_1_2_2_5_'></a>[Navigating through the \"Tree\" of HTML Elements](#toc0_)\n",
    "\n",
    "Beautiful Soup provides a robust set of tools that allow you to traverse and explore the hierarchical structure of an HTML document, often referred to as the \"tree\". \n",
    "\n",
    "To access child elements directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a tag from the soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all h4 elements in all divs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will first locate the initial `div` element present in the Beautiful Soup object. Subsequently, it will fetch all `h4` elements contained within that `div`.\n",
    "\n",
    "But what if you need to retrieve a specific child by its position, say the second child?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the second element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_3_'></a>[Creating a DataFrame with the data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of getting names and prices separately, we can target the whole component, and extract the name and price from each bicycle component in a more structured manner. By targeting this whole component tag, we can ensure that we are extracting information for the same product (i.e., the name and price correspond to the same bicycle).\n",
    "\n",
    "Here's how we can achieve this:\n",
    "\n",
    "1. **Targeting the Whole Component**:\n",
    "   - Instead of targeting individual tags for names and prices, we target the main component that houses both the name and price.\n",
    "   - By visually inspecting the HTML, we can see that:\n",
    "       - The information for each bicycle (name, price, etc.) is grouped together under a `<section>` tag. \n",
    "       - The `class` attribute of this `<section>` tag is `de-ProductTile-info`. This class seemed specific to the product tile and thus, a good candidate to use for extraction.\n",
    "   \n",
    "2. **Iterating through Components**:\n",
    "   - For each such component, extract the name and the price.\n",
    "   \n",
    "3. **Storing Data**:\n",
    "   - Store the extracted data in lists, which can then be used to create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lists to store extracted data\n",
    "bicycle_names = []\n",
    "prices = []\n",
    "\n",
    "# Find all components\n",
    "\n",
    "for component in components:\n",
    "    # Extract bicycle name\n",
    "    \n",
    "    # Extract price\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Bicycle_Name': bicycle_names,\n",
    "    'Price': prices\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could clean even more our dataset so the price can be a float, and we can easily make operations with it. This means, we shouldnt have range of prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_4_'></a>[ðŸ’¡ Check for understanding](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a raw HTML content of a product list from an online store. Your task is to extract the following details for each product:\n",
    "\n",
    "- Bicycle Name\n",
    "- Bicycle Price\n",
    "- URL for the product details\n",
    "- URL for the product image\n",
    "\n",
    "Write a function `extract_bike_info` that takes in the HTML content and returns a pandas DataFrame with the above columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Hint</b></summary>\n",
    "\n",
    "In order to get the product image, might be a good idea to use the `article` tag with the class `de-ProductTile` since based on the HTML structure, this `article` tag encapsulates the entire product, including both the image and the product details. This allows us to more easily access all the relevant details for each product without having to jump around different sections.\n",
    "\n",
    "If we were to only use `soup.find_all('section', class_='de-ProductTile-info')`, we'd be focusing solely on the product details section and would then need a separate approach to extract the image URL. By starting with the `article` tag, we're able to extract all the needed data in a more cohesive and streamlined manner.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** clean the price column so you can make numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function should show up a dataframe here\n",
    "df = extract_bike_info(soup)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_5_'></a>[Scraping many pages](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with a limited number of bicycles, all products are conveniently displayed on a single page. But what if there were numerous products necessitating pagination across multiple pages?\n",
    "\n",
    "Consider the 'deals' collection. By navigating to the end of its first page on the website, we can observe pagination links. Transitioning to the second page results in a change in the URL:\n",
    "\n",
    "From: \n",
    "\"https://www.decathlon.com/collections/deals\"\n",
    "To: \n",
    "\"https://www.decathlon.com/collections/deals?page=2\"\n",
    "\n",
    "This pattern in the URL can be leveraged to generate a series of URLs for web scraping.\n",
    "\n",
    "Please note: Depending on the current offers available at the time of this lesson, pagination might not be present. If that's the case, explore other product categories that have a substantial number of items, resulting in multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [f\"https://www.decathlon.com/collections/deals?page={pag}\" for pag in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets build a df for each URL using our function from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_df_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at our results, and compare it with the website, you'll see that its not returning all the products. Each page has more than 9 products, and its only returning 9 on each page.\n",
    "\n",
    "This could be because the content is dynamic. \n",
    "\n",
    "**Dynamic Content**: Many modern websites use JavaScript to load content dynamically. When you make a request using libraries like `requests`, you're only getting the initial HTML content. Any content loaded dynamically via JavaScript after the initial page load won't be captured. In such cases, tools like Selenium are used because they can interact with the JavaScript of the page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_2_6_'></a>[CSS selectors](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSS selectors are patterns used to select and manipulate one or more elements in an HTML or XML document. When web scraping with Python, CSS selectors can be used to target specific elements of interest within the page's content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select` method in BeautifulSoup allows you to pass a CSS selector and returns a list of elements matching that selector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Tag Selector**: Targets elements by their tag name.\n",
    "   - `p`: selects all `<p>` elements.\n",
    "   - `soup.select(\"p\")`\n",
    "\n",
    "2. **Class Selector**: Targets elements by their class attribute.\n",
    "   - `.classname`: selects all elements with `class=\"classname\"`.\n",
    "   - If class name has spaces, they must be changed by `.`\n",
    "   - `soup.select(\".classname\")`\n",
    "   - To combine both, we can have `soup.select(\"tagname.classname\")`\n",
    "\n",
    "3. **Descendant Selector**: Targets an element that is a descendant of another element.\n",
    "   - `div p`: selects all `<p>` elements inside a `<div>` element.\n",
    "   - `.class1 .class2`: selects all elements with class2 that is a descendant of an element with class1.\n",
    "   \n",
    "4. **Attribute Selector**: Targets elements based on their attributes and values.\n",
    "   - `a[href]`: selects all `<a>` elements with an `href` attribute.\n",
    "   - `a[href=\"https://www.example.com\"]`: selects all `<a>` elements with an `href` value of \"https://www.example.com\".\n",
    "\n",
    "And more...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Tag Selector**:\n",
    "   - **`article`**: This would select all `<article>` elements on the page.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all article tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Class Selector**:\n",
    "   - **`.de-ProductTile`**: This would select all elements with the class `de-ProductTile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all elements with class .de-ProductTile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine both, we can have `soup.select(\"tagname.classname\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without CSS selectors we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, using CSS selectors, which is a universal syntax, you can try and find `tag_name.class_name`. If class name has spaces, they must be changed by `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Descendant Selector**:\n",
    "   - **`.de-ProductTile .de-ProductTile-title`**: This would select all elements with the class `de-ProductTile-title` that are descendants of elements with the class `de-ProductTile`.\n",
    "   - **`article h4`**: This would select all `<h4>` elements that are descendants of `<article>` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .de-ProductTile-title descendants of .de-ProductTile class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h4 descendants of article tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many spans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many spans inside spans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many spans inside spans inside spans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.giphy.com/media/3oEjHE6anD68swMCyI/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many span inside div inside div inside div ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Beautiful Soup selectors](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a combination of `find`, `find_all`, and `select` methods to navigate and locate the elements you're interested in more efficiently. Here's how you can use them together:\n",
    "\n",
    "1. **Using `find` or `find_all` to Narrow Down the Search Scope**:\n",
    "   \n",
    "   Initially, you can use `find` or `find_all` to narrow down your search to a specific section of the HTML document.\n",
    "\n",
    "   ```python\n",
    "   section = soup.find('div', class_='product-section')\n",
    "   ```\n",
    "\n",
    "2. **Using `select` to Further Locate Elements**:\n",
    "\n",
    "   After narrowing down the section, you can use the `select` method to locate elements using CSS selectors, which allow for more complex queries. The `select` method can be used on a BeautifulSoup object or on a Tag object (like the one retrieved in step 1).\n",
    "\n",
    "   ```python\n",
    "   product_links = section.select('a.product-link')\n",
    "   ```\n",
    "\n",
    "In this snippet:\n",
    "- First, we locate a section of the webpage using `find`.\n",
    "- Then, within that section, we locate all `a` elements with the class `'product-link'` using `select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find details for the first product\n",
    "\n",
    "# Extract the main information about the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since its a list we need to access the element to get the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_3_'></a>[More examples (self-guided)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc4_1_3_1_'></a>[BBC](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets scrape the BBC to gather some information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the hyperlinks to images from the BBC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.bbc.com/\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tags = soup.find_all(\"img\") # We get all the image elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_tags) # Lets see how many we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tags[1] # For example, lets look at the second one to see how we can get the actual URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the get method to get the src attribute which contains the URL to the image\n",
    "img_tags[1].get(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the top menu of the BBC, we see that we have the `nav` element with the class `orbit-header-links international`. To get the names from the menu, we need to locate all the span elements inside this nav element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the nav element with the specified class\n",
    "nav_element = soup.find('nav', class_='orbit-header-links international')\n",
    "\n",
    "# Find all span elements inside the nav element\n",
    "menu_names = [span.get_text() for span in nav_element.find_all('span')]\n",
    "\n",
    "# Print the menu names\n",
    "for name in menu_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Comments](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always recommended to check for the availability of an **API** (we'll see next lesson) before resorting to web scraping for the following reasons:\n",
    " * It is generally much easier to use\n",
    " * APIs are usually well-documented\n",
    " * Utilizing APIs is often preferred by server administrators\n",
    "\n",
    "Refer to the `robots.txt` file on a website (by doing `www.example.com/robots.txt`) to understand the server's guidelines and limitations regarding web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[Summary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Web Technologies**:\n",
    "   - **HTML**: This is the markup language that holds the content of the webpage. It is the primary target when we engage in web scraping.\n",
    "   - **CSS**: Cascading Style Sheets are used to describe the look and formatting of a document written in HTML. \n",
    "   - **JavaScript**: This is a scripting language used to create and control dynamic website content.\n",
    "\n",
    "2. **HTML Structure**:\n",
    "   - **Hierarchical**: HTML documents are structured hierarchically, meaning elements are nested within other elements, forming a tree-like structure.\n",
    "   - **Tags**: These are the building blocks of HTML, defining elements that hold different types of content.\n",
    "   - **Attributes**: HTML tags can have attributes, which define properties of an element and are used to set various characteristics such as class, ID, and style.\n",
    "\n",
    "3. **Web Scraping Tools**:\n",
    "   - **Requests**: A Python library that allows you to send HTTP requests to get the HTML content of a webpage.\n",
    "   - **Beautiful Soup**: A Python library that facilitates the programmatic analysis of HTML, helping in parsing the HTML and navigating the parse tree.\n",
    "   - **Selenium**: In cases where the webpage content is dynamic, generated using JavaScript, a tool like Selenium becomes necessary. Selenium can interact with JavaScript to load dynamic content, making it accessible for scraping.\n",
    "   \n",
    "4. **Finding and Selecting Elements**:\n",
    "   - **Selection by Tag, Class, and ID**: We can find elements using various attributes such as their tag name, class name, or ID.\n",
    "   - **CSS Selectors**: These are patterns used to select elements more complexly, leveraging the relationships between different elements to find them in numerous ways.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_4_'></a>[Further materials](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Web archive](http://web.archive.org/): find historical webpages state in the past!!\n",
    "\n",
    "Articles:\n",
    "- [Deep versus Dark Web](https://www.britannica.com/story/whats-the-difference-between-the-deep-web-and-the-dark-web)\n",
    "\n",
    "Videos:\n",
    "- [How does the internet work?](https://www.youtube.com/watch?v=x3c1ih2NJEg) (9 min) - also seen in class \n",
    "- [How are packets transmitted?](https://www.youtube.com/watch?v=7_LPdttKXPc) (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_4_1_'></a>[How to Solve a 403 Error](#toc0_)\n",
    "\n",
    "When you get a `403` status code in response to a web request, it means \"Forbidden.\" The server understands your request, but it refuses to fulfill it. This is often a measure by websites to prevent web scraping or automated access.\n",
    "\n",
    "Here's why you might get a `403 Forbidden` error:\n",
    "\n",
    "1. **User-Agent**: Many websites block requests that don't have a standard web browser User-Agent. The default User-Agent of the `requests` library often gets blocked.\n",
    "2. **Robots.txt**: This is a file websites use to guide web crawlers about which pages or sections of the site shouldn't be processed or scanned. Respect it.\n",
    "3. **Rate Limiting**: Websites might block you if you make too many requests in a short period.\n",
    "And more...\n",
    "\n",
    "To solve it, try the following, starting from the user-agent:\n",
    "\n",
    "1. **Change the User-Agent**:\n",
    "   You can mimic a request from a web browser by setting a User-Agent header.\n",
    "   ```python\n",
    "   headers = {\n",
    "       \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "   }\n",
    "   response = requests.get(url, headers=headers)\n",
    "   ```\n",
    "\n",
    "2. **Use a Web Scraper Library**:\n",
    "   Libraries like Scrapy or Selenium can help bypass restrictions, especially when JavaScript rendering is involved.\n",
    "\n",
    "3. **Respect `robots.txt`**:\n",
    "   Always check `https://www.example.com/robots.txt` (replace `example.com` with the website's domain) to see which URLs you're allowed to access.\n",
    "\n",
    "4. **Rate Limiting**:\n",
    "   Implement delays in your requests using `time.sleep(seconds)` to avoid hitting rate limits.\n",
    "\n",
    "5. **Use Proxies or VPN**:\n",
    "   Rotate IP addresses or use a VPN service if the server has blocked your IP.\n",
    "\n",
    "6. **Sessions & Cookies**:\n",
    "   Some websites might require maintaining sessions or handling cookies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_4_2_'></a>[How to show an image from a URL](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "response = requests.get('https://i.imgflip.com/7zldoz.jpg')\n",
    "Image.open(BytesIO(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
