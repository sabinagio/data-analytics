{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Imbalanced Data](#toc1_)    \n",
        "- [A relatively bad model](#toc2_)    \n",
        "  - [Changing weights internally](#toc2_1_)    \n",
        "- [Oversampling / undersampling](#toc3_)    \n",
        "  - [Oversampling](#toc3_1_)    \n",
        "  - [Undersampling](#toc3_2_)    \n",
        "- [SMOTE](#toc4_)    \n",
        "- [Acknowledgements](#toc5_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Imbalanced Data](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Why is this important? Most of the events we are trying to predict (e.g. fraudulent card transactions, disease, customer churn) are **minority** events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You know the drill...\n",
        "# What library do I need to install? :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEPXZPU04TRg"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Zl7PPAbNcAM"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KidUt5_o4XdS",
        "outputId": "3b8b57a3-46dd-45c8-c659-c9d81cb35ecd"
      },
      "outputs": [],
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/diabetes.csv')\n",
        "diabetes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E18JD9ghdHLp",
        "outputId": "40eadfb0-090a-4afb-d167-d63cd6bbce3e"
      },
      "outputs": [],
      "source": [
        "diabetes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes.Outcome.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> While there are more imbalanced datasets, we have a significant imbalance and the cost of failing to detect the minority class is quite high (lack of diagnosis of diabetes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "s2NDF-DI4llM",
        "outputId": "86b96c88-40ad-4114-eb2e-94bb1b4abf6a"
      },
      "outputs": [],
      "source": [
        "count_classes = pd.value_counts(diabetes['Outcome'])\n",
        "count_classes.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdVciAgE4r91"
      },
      "outputs": [],
      "source": [
        "X = diabetes.drop('Outcome', axis=1)\n",
        "y = diabetes['Outcome']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEBDEsrz4uYY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[A relatively bad model](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9plw4nij43b0",
        "outputId": "7f550546-4842-436a-d2c8-d756d17ad7a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "LR.fit(X_train, y_train)\n",
        "LR.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> While accuracy is not absolutely terrible, a closer look reveals some serious problems:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYTOjlLV477o",
        "outputId": "22d8c2ac-2489-406c-b491-1d284f57d896"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "pred = LR.predict(X_test)\n",
        "\n",
        "print(\"precision: \",precision_score(y_test,pred))\n",
        "print(\"recall: \",recall_score(y_test,pred))\n",
        "print(\"f1: \",f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> We fail to identify 40%+ of diabetes cases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = pd.DataFrame(confusion_matrix(y_test, pred))\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz2n-fZ35A2V",
        "outputId": "9048a3fa-89de-411f-a2fa-e98c47361e97"
      },
      "outputs": [],
      "source": [
        "# Rename columns to predicted values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - Pred', 1: 'Yes - Pred'}, axis=1, inplace=True)\n",
        "# Rename rows to real values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - True', 1: 'Yes - True'}, axis=0, inplace=True)\n",
        "px.imshow(cm, text_auto=True, color_continuous_scale='RdBu', color_continuous_midpoint=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Changing weights internally](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "LR.fit(X_train, y_train)\n",
        "LR.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = LR.predict(X_test)\n",
        "\n",
        "print(\"precision: \", precision_score(y_test, pred))\n",
        "print(\"recall: \", recall_score(y_test, pred))\n",
        "print(\"f1: \", f1_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = pd.DataFrame(confusion_matrix(y_test, pred))\n",
        "# Rename columns to predicted values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - Pred', 1: 'Yes - Pred'}, axis=1, inplace=True)\n",
        "# Rename rows to real values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - True', 1: 'Yes - True'}, axis=0, inplace=True)\n",
        "px.imshow(cm, text_auto=True, color_continuous_scale='RdBu', color_continuous_midpoint=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Oversampling / undersampling](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ync9VxfK5LVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Oversampling / undersampling is only to be done on the TRAINING set!** Otherwise we might have test samples leaking into the training set:\n",
        "- **Resampling + Train-Test Split:** X = ABCD -resampling-> AABBCCDD -train test split-> AABBC / CDD   \n",
        "- **Train-Test Split + Resampling:** X = ABCD -train test split-> ABC / D -resampling-> AABBCC / D "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "Z_zew0pq5NxU",
        "outputId": "bd2ea63a-9416-463f-cf8c-5872330c3855"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "display(train.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Oversampling - Resampling](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy6E34fD5SDX"
      },
      "outputs": [],
      "source": [
        "# separate majority/minority classes\n",
        "no_diabetes = train[train['Outcome']==0]\n",
        "yes_diabetes = train[train['Outcome']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "OcBHbQmGb8M-",
        "outputId": "e830238e-7127-45f4-b41d-5273b5f480e8"
      },
      "outputs": [],
      "source": [
        "display(no_diabetes.shape)\n",
        "display(yes_diabetes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gauYiWFF5VJN"
      },
      "outputs": [],
      "source": [
        "# oversample minority\n",
        "yes_diabetes_oversampled = resample(yes_diabetes, #<- sample from here\n",
        "                                    replace=True, #<- we need replacement, since we don't have enough data otherwise\n",
        "                                    n_samples = len(no_diabetes),#<- make both sets the same size\n",
        "                                    random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "flJ86yzu5YuG",
        "outputId": "bf5901b5-2950-4c39-eb7a-b3e798322dbc"
      },
      "outputs": [],
      "source": [
        "# both sets are now of a reasonable size\n",
        "display(no_diabetes.shape)\n",
        "display(yes_diabetes_oversampled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1VOIOECx5ZX8",
        "outputId": "50747e9a-4335-47e1-d1de-aea3c5cf5af1"
      },
      "outputs": [],
      "source": [
        "train_oversampled = pd.concat([no_diabetes, yes_diabetes_oversampled])\n",
        "train_oversampled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e8ZfPsj5cms"
      },
      "outputs": [],
      "source": [
        "y_train_over = train_oversampled['Outcome'].copy()\n",
        "X_train_over = train_oversampled.drop('Outcome',axis = 1).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Our Logistic Regression, while still not amazing, has improved substantially! Especially at detecting instances of diabetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oJqoMV5dIl",
        "outputId": "88ed6dd7-eb20-4378-aa80-b95f28d8fc5f"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression(max_iter=1000)\n",
        "LR.fit(X_train_over, y_train_over)\n",
        "pred = LR.predict(X_test)\n",
        "\n",
        "print(\"precision: \",precision_score(y_test,pred))\n",
        "print(\"recall: \",recall_score(y_test,pred))\n",
        "print(\"f1: \",f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = pd.DataFrame(confusion_matrix(y_test, pred))\n",
        "# Rename columns to predicted values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - Pred', 1: 'Yes - Pred'}, axis=1, inplace=True)\n",
        "# Rename rows to real values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - True', 1: 'Yes - True'}, axis=0, inplace=True)\n",
        "px.imshow(cm, text_auto=True, color_continuous_scale='RdBu', color_continuous_midpoint=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Undersampling](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiKDO31U5sRx"
      },
      "outputs": [],
      "source": [
        "# undersample majority\n",
        "no_diabetes_undersampled = resample(no_diabetes, #<- downsample from here\n",
        "                                    replace=False, #<- no need to reuse data now, we have an abundance\n",
        "                                    n_samples = len(yes_diabetes),\n",
        "                                    random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Both sets are the same size - small, but balanced, and no repeated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "eWrdzhc1DBI2",
        "outputId": "d362a253-1e5d-453a-f0bb-6d69a3c97e96"
      },
      "outputs": [],
      "source": [
        "display(yes_diabetes.shape)\n",
        "display(no_diabetes_undersampled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jNAshNet50_F",
        "outputId": "f4a1b283-4226-41cd-cdb4-4539bc421103"
      },
      "outputs": [],
      "source": [
        "train_undersampled = pd.concat([yes_diabetes,no_diabetes_undersampled])\n",
        "train_undersampled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abiZ3rTF51sd"
      },
      "outputs": [],
      "source": [
        "y_train_under = train_undersampled['Outcome'].copy()\n",
        "X_train_under = train_undersampled.drop('Outcome',axis = 1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqczGsfc53No",
        "outputId": "cbc3ba11-40e4-4af5-a389-7b19d723c836"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "LR.fit(X_train_under, y_train_under)\n",
        "pred = LR.predict(X_test)\n",
        "\n",
        "print(\"precision: \",precision_score(y_test,pred))\n",
        "print(\"recall: \",recall_score(y_test,pred))\n",
        "print(\"f1: \",f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = pd.DataFrame(confusion_matrix(y_test, pred))\n",
        "# Rename columns to predicted values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - Pred', 1: 'Yes - Pred'}, axis=1, inplace=True)\n",
        "# Rename rows to real values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - True', 1: 'Yes - True'}, axis=0, inplace=True)\n",
        "px.imshow(cm, text_auto=True, color_continuous_scale='RdBu', color_continuous_midpoint=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[SMOTE](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "insSvyeh5_cN"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> A bit of magic, you can find documentation here: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html. By default, takes a 5-neightbour KNN to build a new point:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHeF2AAU6HSU"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=123,sampling_strategy=1.0)\n",
        "X_train_SMOTE, y_train_SMOTE = sm.fit_resample(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "J0mA3xMknUwm",
        "outputId": "462dc30a-085d-403c-d1d4-b65c08533909"
      },
      "outputs": [],
      "source": [
        "y_train_SMOTE.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Yet another small improvement, but bear in mind that we saved 12 hypothetical people with these \"small improvements\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2RUBJ9o6JXX",
        "outputId": "ebee25bc-a56a-446f-ef8d-29b5c162c6d2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
        "pred = LR.predict(X_test)\n",
        "\n",
        "print(\"precision: \",precision_score(y_test, pred))\n",
        "print(\"recall: \",recall_score(y_test, pred))\n",
        "print(\"f1: \",f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = pd.DataFrame(confusion_matrix(y_test, pred))\n",
        "# Rename columns to predicted values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - Pred', 1: 'Yes - Pred'}, axis=1, inplace=True)\n",
        "# Rename rows to real values - 0 = No diabetes, 1 = Diabetes\n",
        "cm.rename({0: 'No - True', 1: 'Yes - True'}, axis=0, inplace=True)\n",
        "px.imshow(cm, text_auto=True, color_continuous_scale='RdBu', color_continuous_midpoint=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc5_'></a>[Acknowledgements](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thank you, David Henriques, for your awesome lesson structure and content!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
