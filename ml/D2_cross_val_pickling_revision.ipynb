{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Bias-variance trade-off](#toc1_)    \n",
    "  - [From previous class: Breast cancer dataset](#toc1_1_)    \n",
    "- [Cross Validation](#toc2_)    \n",
    "    - [**What is cross-validation?**](#toc2_1_1_)    \n",
    "    - [**Why cross-validation?**](#toc2_1_2_)    \n",
    "  - [Stratified K-Fold Cross Validation](#toc2_2_)    \n",
    "  - [Repeated KFold](#toc2_3_)    \n",
    "    - [**How to choose K?**](#toc2_3_1_)    \n",
    "  - [Shuffle Split](#toc2_4_)    \n",
    "  - [Stratified Shuffle Split](#toc2_5_)    \n",
    "  - [Time Series Cross Validation](#toc2_6_)    \n",
    "  - [Extra: Leave-One-Out Cross-Validation](#toc2_7_)    \n",
    "- [Pickling](#toc3_)    \n",
    "  - [Save the model](#toc3_1_)    \n",
    "  - [Load the model](#toc3_2_)    \n",
    "  - [Save the data](#toc3_3_)    \n",
    "  - [Load the data](#toc3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Bias-variance trade-off](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*9hPX9pAO3jqLrzt0IE3JzA.png)  \n",
    "(Source: [Understanding the Bias-Variance Tradeoff, Medium](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is bias?**\n",
    "> Bias is the **difference between the average prediction of our model and the correct value** which we are trying to predict. \n",
    "> Models with high bias pay very little attention to the training data and oversimplifies the model. It always leads to high error on training and test data. [$^{[1]}$](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is variance?**\n",
    "\n",
    "> Variance is the **variability of model prediction for a given data point** or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasnâ€™t seen before. As a result, such models perform very well on training data but has high error rates on test data. [$^{[1]}$](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Extra: The maths of it all](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html)**  \n",
    "\n",
    "$\\underbrace{E_{\\mathbf{x}, y, D} \\left[\\left(h_{D}(\\mathbf{x}) - y\\right)^{2}\\right]}_\\mathrm{Expected\\;Test\\;Error} = \\underbrace{E_{\\mathbf{x}, D}\\left[\\left(h_{D}(\\mathbf{x}) - \\bar{h}(\\mathbf{x})\\right)^{2}\\right]}_\\mathrm{Variance} + \\underbrace{E_{\\mathbf{x}, y}\\left[\\left(\\bar{y}(\\mathbf{x}) - y\\right)^{2}\\right]}_\\mathrm{Noise} + \\underbrace{E_{\\mathbf{x}}\\left[\\left(\\bar{h}(\\mathbf{x}) - \\bar{y}(\\mathbf{x})\\right)^{2}\\right]}_\\mathrm{Bias^2}$\n",
    "\n",
    "**What is noise?**  \n",
    "\n",
    "> This error measures ambiguity due to your data distribution and feature representation. You can never beat this, it is an aspect of the data. [$^{[2]}$](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do we want?**\n",
    "\n",
    "A model complex enough to understand the data but not so complex that it memorizes the data.\n",
    "\n",
    "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)  \n",
    "\n",
    "(Source: [Understanding the Bias-Variance Tradeoff, Scott Fortmann-Roe](https://scott.fortmann-roe.com/docs/BiasVariance.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[From previous class: Breast cancer dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset into pandas\n",
    "features = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])\n",
    "labels = pd.Series(cancer['target'], name = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display features & labels\n",
    "display(features)\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and fit model\n",
    "rf_model = RandomForestClassifier(max_depth=3, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review overall accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Train accuracy:', accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print('Test accuracy:', accuracy_score(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Cross Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[**What is cross-validation?**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgs.search.brave.com/tEBDW7f_GRHyGUhYVI0mmwKHv5NYPdYEFKxDqBUF3mk/rs:fit:860:0:0/g:ce/aHR0cHM6Ly93d3cu/c2VjdGlvbi5pby9l/bmdpbmVlcmluZy1l/ZHVjYXRpb24vaG93/LXRvLWltcGxlbWVu/dC1rLWZvbGQtY3Jv/c3MtdmFsaWRhdGlv/bi81LWZvbGQtY3Yu/anBlZw)  \n",
    "(Source: [How to Implement K fold Cross-Validation in Scikit-Learn, Section.io](https://www.section.io/engineering-education/how-to-implement-k-fold-cross-validation/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[**Why cross-validation?**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are using the test set accuracy to tweak our hyperparameters, we are indirectly feeding our model informaton about the test set, i.e. which hyperparameters work best with the test set. Cross validation helps solve this problem by averaging across multiple testing scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Stratified K-Fold Cross Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be what you always do whenever you do hyperparameter tuning, i.e. choose the optimal parameters for your model. However, this doesn't work if your traininng process is either too expensive or too long. The cross-validation should always be **stratified based on the target** and this is what `sklearn` does by default with its cross-validation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_009.png)  \n",
    "(Source: [3.1. Cross-validation: evaluating estimator performance, scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying an example of cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Initialize model and cross validate with 10 folds\n",
    "results = cross_validate(rf_model, features, labels, cv=10)\n",
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review test scores per validation set\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review overall test score\n",
    "results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different scoring metric\n",
    "results = cross_validate(rf_model, features, labels, cv=10, scoring='recall')\n",
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review overall test score\n",
    "results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Repeated KFold](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Initialize model and cross validate with 10 folds\n",
    "scores = cross_val_score(rf_model, features, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different scoring metric\n",
    "scores = cross_val_score(rf_model, features, labels, scoring='recall', cv=cv, n_jobs=-1)\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_1_'></a>[**How to choose K?**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Typical values for k are k=3, k=5, and k=10, with 10 representing the most common value. This is because, given extensive testing, 10-fold cross-validation provides a good balance of low computational cost and low bias in the estimate of model performance as compared to other k values and a single train-test split. [$^{[3]}$](https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Shuffle Split](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_008.png)  \n",
    "(Source: [3.1. Cross-validation: evaluating estimator performance, scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The ShuffleSplit iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets. It is possible to control the randomness for reproducibility of the results by explicitly seeding the random_state pseudo random number generator. [$^{[4]}$](https://scikit-learn.org/stable/modules/cross_validation.html#shufflesplit)\n",
    "\n",
    "Even though Shuffle Split is a strategy for cross-validation, it is recommended to use the Stratified Shuffle Split, as it keeps the proportion of target classes equal across all train-validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Stratified Shuffle Split](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> StratifiedShuffleSplit is a variation of ShuffleSplit, which returns stratified splits, i.e which creates splits by preserving the same percentage for each target class as in the complete set. [$^{[4]}$](https://scikit-learn.org/stable/modules/cross_validation.html#shufflesplit)\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_012.png)  \n",
    "(Source: [3.1. Cross-validation: evaluating estimator performance, scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Set up the cross validator\n",
    "cv_sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "cv_sss.get_n_splits(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the stratified shuffle split does\n",
    "for i, (train_indices, test_indices) in enumerate(cv_sss.split(features, labels)):\n",
    "    print('Split no:', i)\n",
    "    print('Train indices:', train_indices[:5])\n",
    "    print('Test indices:', test_indices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now see it in action! ...manually\n",
    "results = []\n",
    "for train_index, test_index in cv_sss.split(features, labels):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    pred = rf_model.predict(X_test)\n",
    "    results.append(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now using the sklearn \n",
    "scores = cross_val_score(rf_model, features, labels, scoring='accuracy', cv=cv_sss, n_jobs=-1)\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[Time Series Cross Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)   \n",
    "(Source: [3.1. Cross-validation: evaluating estimator performance, scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = pd.read_csv('https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/occupancy.csv')\n",
    "occupancy.set_index('date', inplace=True)\n",
    "occupancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = occupancy.drop('Occupancy', axis=1)\n",
    "labels = occupancy['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Set up the cross validator\n",
    "ts_sss = TimeSeriesSplit(n_splits=6)\n",
    "ts_sss.get_n_splits(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review how the time series split works\n",
    "for i, (train_index, test_index) in enumerate(ts_sss.split(features)):\n",
    "    print('Split no:', i)\n",
    "    print('Train set size:', len(train_index))\n",
    "    print('Test set size:', len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And see it in action!... manually\n",
    "results = []\n",
    "for train_index, test_index in ts_sss.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    pred = rf_model.predict(X_test)\n",
    "    results.append(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now using the sklearn \n",
    "scores = cross_val_score(rf_model, features, labels, scoring='accuracy', cv=ts_sss, n_jobs=-1)\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_7_'></a>Extra: [Leave-One-Out Cross-Validation](https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Pickling](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pickle many things: ML models, pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Save the model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model, open('rf_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Load the model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_model.pkl', 'rb') as file:\n",
    "    rf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pickle.load(open('rf_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Save the data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('train_data.pkl')\n",
    "y_train.to_pickle('train_label.pkl')\n",
    "\n",
    "X_test.to_pickle('test_data.pkl')\n",
    "y_test.to_pickle('test_label.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Load the data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('train_data.pkl')\n",
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
