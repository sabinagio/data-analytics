{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Feature engineering - I](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Feature engineering - I](#toc1_)    \n",
        "  - [Formal transformations](#toc1_1_)    \n",
        "    - [One-hot encoding](#toc1_1_1_)    \n",
        "    - [Label Encoding](#toc1_1_2_)    \n",
        "    - [Binning / Discretization](#toc1_1_3_)    \n",
        "      - [`cut`: range-based, different sized bins](#toc1_1_3_1_)    \n",
        "      - [`qcut`: quartile-based, equally-sized bins](#toc1_1_3_2_)    \n",
        "- [Modelling](#toc2_)    \n",
        "  - [Train-test split](#toc2_1_)    \n",
        "  - [Training & evaluation](#toc2_2_)    \n",
        "- [Feature engineering - II](#toc3_)    \n",
        "  - [Formal transformations](#toc3_1_)    \n",
        "    - [Normalization](#toc3_1_1_)    \n",
        "    - [Correlation Tresholds](#toc3_1_2_)    \n",
        "  - [Semantic transformations](#toc3_2_)    \n",
        "- [Acknowledgements](#toc4_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4oll1EPBrve"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> The following dataset emulates the joint information from a company's HR file and medical exam (not REAL data!) - our goal is to try to approximate salaries from this information. We have chosen to use a `KNN regression` as our model (distance-based)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rBFv9gHrBuYk",
        "outputId": "a4a49e74-f910-4133-c28a-4b3398943d89"
      },
      "outputs": [],
      "source": [
        "salary = pd.read_csv('https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/salaries.csv')\n",
        "salary.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_1_'></a>[Formal transformations](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ns2zeYjGHC7",
        "outputId": "c8e7bbc2-364d-43f2-f8e7-888bbd705661"
      },
      "outputs": [],
      "source": [
        "salary['Daltonic'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "salary['Daltonic'].fillna('No Daltonism', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_1_1_'></a>[One-hot encoding](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Besides `pd.dummies`, you can use `sklearn.preprocessing.OneHotEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "awMDa2KpB5GO",
        "outputId": "439b9c0e-4d56-4e2a-ffb8-91afb049b3ad"
      },
      "outputs": [],
      "source": [
        "dalt_transformed = pd.get_dummies(salary['Daltonic'], drop_first=True)\n",
        "dalt_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dalt_transformed[np.NaN].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Kfz6ZMQIDDmX",
        "outputId": "c770e5b0-52b4-4f03-fc83-c990bccad748"
      },
      "outputs": [],
      "source": [
        "salary_transformed = pd.merge(left = salary,\n",
        "                              right = pd.get_dummies(salary['Daltonic'],prefix='Daltonic',drop_first=True),\n",
        "                              left_index=True,\n",
        "                              right_index=True)\n",
        "salary_transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_1_2_'></a>[Label Encoding](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can do it by direct mapping of values or by calling the `sklearn.preprocessing.LabelEncoder`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "salary_transformed['Experience_label'] = salary_transformed['Experience'].replace({'Junior':0,'Senior':1})\n",
        "salary_transformed['Gender_label'] = salary_transformed['Gender'].replace({'Male':0,'Female':1})\n",
        "salary_transformed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_1_3_'></a>[Binning / Discretization](#toc0_)\n",
        "\n",
        "Binning is used to turn numeric features into categorical ones. In this case we're not going to use categorical features, but for the record:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_3_1_'></a>[`cut`: range-based, different sized bins](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEP6NxYxudbN",
        "outputId": "5721a366-761e-4fe7-c56e-dd2244c5aab2"
      },
      "outputs": [],
      "source": [
        "# Binning: \n",
        "series = pd.cut(salary['Height'], 5, labels=['very short','short','average','tall','very tall'])\n",
        "display(series.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check calculation for normal binning\n",
        "from dfply import *\n",
        "height_diff = salary['Height'].max() - salary['Height'].min()\n",
        "no_bins = 5\n",
        "(salary >> mask(X.Height < (X.Height.min() + height_diff / no_bins)) >> select('Salary')).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_3_2_'></a>[`qcut`: quartile-based, equally-sized bins](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Binning: \n",
        "pd.qcut(salary['Height'], 5, labels=['very short','short','average','tall','very tall']).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "TO7ZBPKfvjE6",
        "outputId": "f60a5a92-9e99-4a46-fb37-5e9ecc597c1f"
      },
      "outputs": [],
      "source": [
        "salary_transformed['Height_classes'] = pd.cut(salary['Height'],5,labels=['very short','short','average','tall','very tall'])\n",
        "salary_transformed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Modelling](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> We can now drop the non-numerics and keep only numeric columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Jm3zu28ODID0",
        "outputId": "8b563e1c-3c66-4206-e9a2-21d7f7bf5f82"
      },
      "outputs": [],
      "source": [
        "salary_transformed = salary_transformed.drop(columns=['Experience','Gender','Daltonic','Height_classes', 'Company'])\n",
        "salary_transformed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Train-test split](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "g-8iZSgKW4oP",
        "outputId": "ec274513-5b7a-4d6d-d806-80cad5ef9432"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(salary_transformed.drop(columns=['Salary']), salary_transformed['Salary'], random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Training & evaluation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We evaluate our model using the `MSE score` (mean squared error): $(Salary_{real} - Salary_{predicted})^2$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a33qj6ZLDqwQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# create knn, don't forget Hyperparameter\n",
        "knn = KNeighborsRegressor(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit our model and predict on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpUX5OJwDsux",
        "outputId": "58e0cad3-8b23-47bb-85b2-81c6a1e45bd4"
      },
      "outputs": [],
      "source": [
        "knn.fit(X_train, y_train)\n",
        "pred = knn.predict(X_test)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z33xrtDPNQX4",
        "outputId": "45383c2d-765d-47a3-c696-a20c43b64f89"
      },
      "outputs": [],
      "source": [
        "np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2JXMV8VNMjN",
        "outputId": "2f112130-d216-4047-f31d-b53a774b3c68"
      },
      "outputs": [],
      "source": [
        "np.sqrt(mean_squared_error(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Feature engineering - II](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Formal transformations](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_1_'></a>[Normalization](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> We apply a normalization of the features since `flexibility` seems to count 200 times more than `Daltonic_None`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0T-3YdZDujx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create normalization object from scikit learn package, and \"fit\" it to the features in hand\n",
        "normalizer = MinMaxScaler()\n",
        "normalizer = normalizer.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 💡**Notice how we only use the **X_train** data to fit?**\n",
        "\n",
        "> We want to **use only the training data to normalize** (establishing maximum and minimum values) to avoid `data leakage` from the test dataset. If we used data from the test dataset, the test results would be biased by having some info from the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: We can use other scalers too, such as `sklearn.preprocessing.StandardScaler` or `sklearn.preprocessing.RobustScaler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "r1zXzz0MuGOY",
        "outputId": "aa3b7516-077d-4d9e-aa57-3b2fc6487283"
      },
      "outputs": [],
      "source": [
        "# now that we have our normalizer we use it for both training and testing (and in the future for unseen data as well!)\n",
        "X_train_normalized = normalizer.transform(X_train)\n",
        "X_train_normalized = pd.DataFrame(X_train_normalized,columns=X_train.columns)\n",
        "X_train_normalized.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIdW6y_mD6_g",
        "outputId": "7eefdd33-0918-47f2-f297-183e6685376a"
      },
      "outputs": [],
      "source": [
        "# let's see if this normalization improves our model\n",
        "# creating model\n",
        "knn = KNeighborsRegressor(n_neighbors=3)\n",
        "# training the model on normalized data\n",
        "knn.fit(X_train_normalized, y_train)\n",
        "# testing algorithm on normalized test\n",
        "pred = knn.predict(X_test_normalized)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_test,pred))\n",
        "#much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_2_'></a>[Correlation Tresholds](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Let's see if our variables are too dependent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zdbrsbtYD_QJ",
        "outputId": "948bdbf9-6eaa-4442-f1ab-10f36ce3afcd"
      },
      "outputs": [],
      "source": [
        "X_train_normalized.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> As you've seen before, a very common way to visualize the results discussed above is to create a correlation matrix. Only the lower triangular component of the matrix is shown due to the fact that the upper and lower (triangular) parts of the matrix are equal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5DfCvvd1EBLy",
        "outputId": "c411f8d6-c44d-4423-c0d6-59c268229f78"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "corr=np.abs(X_train_normalized.corr())\n",
        "\n",
        "#Set up mask for triangle representation\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(14, 14))\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sn.heatmap(corr, mask=mask,  vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "uWDnrSvgcKFB",
        "outputId": "59525133-6c93-4661-a3c4-5f77cbe9d6a5"
      },
      "outputs": [],
      "source": [
        "X_train_normalized.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Very clear that all variables are essentially the same! Except for experience! What is the effect of this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E0d-qW_ED1a"
      },
      "outputs": [],
      "source": [
        "X_train_reduced = X_train_normalized[['Gender_label','Experience_label']]\n",
        "X_test_reduced = X_test_normalized[['Gender_label','Experience_label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4pmBt5EK36",
        "outputId": "1d43fded-43ea-46b1-b4d4-99cd8b921923"
      },
      "outputs": [],
      "source": [
        "# creating our knn model\n",
        "knn = KNeighborsRegressor(n_neighbors=3)\n",
        "# training the model on reduced, normalized data\n",
        "knn.fit(X_train_reduced, y_train)\n",
        "# testing algorithm on reduced, normalized test\n",
        "pred = knn.predict(X_test_reduced)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "2945 * 100 / salary['Salary'].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Semantic transformations](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2XGhRfEuIEon",
        "outputId": "b5a9d7fd-9043-4596-f7c3-176d906cc407"
      },
      "outputs": [],
      "source": [
        "# we want to understand what drives loss of energy in our windfarms\n",
        "energy = pd.read_csv('https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/energy_loss.csv')\n",
        "energy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKcGsAjYIEvK"
      },
      "outputs": [],
      "source": [
        "# let's try to predict it \"raw\"\n",
        "X = energy[['Voltage','Rotation','Stability']]\n",
        "y = energy['Loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR8VIvkZIShb",
        "outputId": "d46ed049-2845-4c6b-83b6-9dc006851950"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X, y)\n",
        "reg.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> However we know the optimal values of `Voltage`, `Rotation` and `Stability` from an engineer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCP6T9wzIUJV"
      },
      "outputs": [],
      "source": [
        "energy_transformed = energy.copy()\n",
        "energy_transformed['Voltage'] = np.square(energy_transformed['Voltage']-100)\n",
        "energy_transformed['Rotation'] = np.square(energy_transformed['Rotation']-150)\n",
        "energy_transformed['Stability'] = np.square(energy_transformed['Stability']-90)\n",
        "X = energy_transformed[['Voltage','Rotation','Stability']]\n",
        "y = energy_transformed['Loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Z43Aq7WTaq9a",
        "outputId": "2c4753a7-2146-4815-8dcd-a56bb1aeb85b"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wSwXMTaIWEC",
        "outputId": "f4aa9148-a96d-40af-b477-bfc69fdcde0f"
      },
      "outputs": [],
      "source": [
        "# the model improves dramatically\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X, y)\n",
        "reg.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[Acknowledgements](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thank you, David Henriques, for your awesome lesson structure and content."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
